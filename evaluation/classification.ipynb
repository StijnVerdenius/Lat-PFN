{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "\n",
    "from initialiser import build_dataset, build_model\n",
    "from config import config\n",
    "import polars as pl\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from util.persist import load_model\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "models_path = \"/data/pfn/models/seeds_paper_1/*/*.ckpt\"\n",
    "\n",
    "\n",
    "def embed(model, tensor):\n",
    "    \n",
    "    embedding_context, _ = model.TS_encoder(\n",
    "        (\n",
    "            torch.linspace(-3, 1, tensor.shape[-2])\n",
    "            .unsqueeze(0)\n",
    "            .unsqueeze(0)\n",
    "            .unsqueeze(-1)\n",
    "            .repeat(tensor.shape[0], 1, 1, 1)\n",
    "            .cuda()\n",
    "        ),\n",
    "        tensor.unsqueeze(1).repeat(1, 1, 1, 1).float().cuda(),\n",
    "    )\n",
    "    return model.avg_pool(model.proj(embedding_context))#[:, 0, :]\n",
    "\n",
    "for model_path in glob(models_path):\n",
    "\n",
    "    seed = model_path.split(\"/\")[-2]\n",
    "\n",
    "    device = \"cuda\"\n",
    "\n",
    "    model_arch = build_model(\n",
    "        width=8,\n",
    "        config=config,\n",
    "        n_outputs=100,\n",
    "        use_mup_parametrization=True,\n",
    "        load_base_shapes=True,\n",
    "        build_base_shapes=True,\n",
    "    )\n",
    "\n",
    "    model = load_model(model_path, model_arch, device)\n",
    "\n",
    "    model = model.to(\"cuda\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    base_path = \"/data/pfn/test_datasets/ucr/UCRArchive_2018/\"\n",
    "\n",
    "    current_set = []\n",
    "\n",
    "    all_preds = None\n",
    "    all_targets = None\n",
    "    \n",
    "\n",
    "    for train_df_name, test_df_name in tqdm(zip(\n",
    "        glob(base_path + \"/*/*_TRAIN.tsv\"), glob(base_path + \"/*/*_TEST.tsv\")\n",
    "    )):\n",
    "        \n",
    "        assert train_df_name.replace(\"_TRAIN.tsv\", \"\") == test_df_name.replace(\"_TEST.tsv\", \"\"), f\"{train_df_name} != {test_df_name}\"\n",
    "\n",
    "        print(\n",
    "            train_df_name.replace(\"_TRAIN.tsv\", \"\")\n",
    "        )\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "        train_df = pd.read_csv(train_df_name, sep=\"\\t\", header=None)\n",
    "        test_df = pd.read_csv(test_df_name, sep=\"\\t\", header=None)\n",
    "\n",
    "        label_to_index = {label: i for i, label in enumerate(sorted(train_df[0].unique()))}\n",
    "\n",
    "        train_df[0] = train_df[0].map(label_to_index)\n",
    "        test_df[0] = test_df[0].map(label_to_index)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # for chunk\n",
    "\n",
    "            train_tensor = (\n",
    "                torch.from_numpy(train_df.to_numpy()[:, 1:])\n",
    "                .cuda()\n",
    "                .float()\n",
    "                .unsqueeze(-1)\n",
    "            ).nan_to_num(0)\n",
    "\n",
    "            batch_size, sequence_length, feature_dim = train_tensor.shape\n",
    "\n",
    "            chunk_size = min(128, int(128 * (786 / sequence_length)))\n",
    "\n",
    "            print(train_tensor.shape, chunk_size)\n",
    "    \n",
    "            train_X = torch.cat(\n",
    "                [\n",
    "                    embed(\n",
    "                        model,\n",
    "                        xx\n",
    "                    )\n",
    "                    for xx in torch.split(train_tensor, chunk_size, dim=0) \n",
    "                ], \n",
    "                0 \n",
    "            ).cpu() \n",
    "            \n",
    "            train_y = train_df.to_numpy()[:, 0]\n",
    "\n",
    "            test_tensor = (\n",
    "                torch.from_numpy(test_df.to_numpy()[:, 1:])\n",
    "                .cuda()\n",
    "                .float()\n",
    "                .unsqueeze(-1)\n",
    "            ).nan_to_num(0)\n",
    "\n",
    "            test_X = torch.cat(\n",
    "                [\n",
    "                    embed(\n",
    "                        model,\n",
    "                        xx\n",
    "                    ) \n",
    "                    for xx in torch.split(test_tensor, chunk_size, dim=0) \n",
    "                ], \n",
    "                0 \n",
    "            ).cpu() \n",
    "\n",
    "            test_y = test_df.to_numpy()[:, 0]\n",
    "        \n",
    "        clf = svm.SVC()\n",
    "        clf.fit(train_X, train_y)\n",
    "\n",
    "        pred = clf.predict(test_X)\n",
    "\n",
    "        acc = (pred == test_y).mean()\n",
    "\n",
    "        print(\n",
    "            f\"{test_df_name.split('/')[-1].split('.')[0]},{acc},{seed}\\n\",\n",
    "            file=open(f\"classification_results.csv\", \"a\")\n",
    "        )\n",
    "\n",
    "        if all_preds is None:\n",
    "            all_preds = pred\n",
    "            all_targets = test_y\n",
    "        else:\n",
    "            all_preds = np.concatenate([all_preds, pred])\n",
    "            all_targets = np.concatenate([all_targets, test_y])\n",
    "\n",
    "\n",
    "    all_acc = (all_preds == all_targets).mean()\n",
    "\n",
    "    print(\n",
    "        f\"Overall,{all_acc},{seed}\\n\",\n",
    "        file=open(f\"classification_results.csv\", \"a\")\n",
    "    )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
